1.
I'm trying to generate a control that interacts with music and lights through sensor control, and I'm not sure if this idea is feasible. I want to combine our previous music visualization ideas, in the p5js part of the creation of a visual image of the music, and then to present the music waveform changes, or call some other library form to combine the music visualization, and then at the same time I don't know if it can be achieved, I want to let the Arduino to control the light flashing according to the music waveform. The general idea is to analyze the waveform, then the led blinks at the same time, or light up according to the order, or have time control, time delayed lighting. The user can switch between different light modes via potentiometers or buttons. chatgpt's idea is that the user can manipulate the music by changing the state of the sensors (e.g. blocking light or applying pressure).
This is just my basic idea, maybe I will change the code later according to the idea. But the basic direction will not change

